{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thin plate Spline Spatial Transformer Network\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "# select GPU on the server\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "# pytorch related package \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "print('pytorch version: ' + torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# math and showcase\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stub for argparse\n",
    "class opts:\n",
    "    def __init__(self):\n",
    "        self.resume = False\n",
    "        self.sess = 'test_run'\n",
    "        self.seed = 35328880\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 10\n",
    "        self.n_grid_density = 4\n",
    "        self.image_size = 28\n",
    "\n",
    "args = opts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "follower: neural network of the original task. For now a simple small convolution neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class follower(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(follower, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "localizer, part of the STN, train on data and output the distortion kernel for TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class localizer(nn.Module):\n",
    "    def __init__(self, args, source_points):\n",
    "        super(localizer, self).__init__()\n",
    "        self.args = args\n",
    "        n_output = args.n_grid_density**2 *2\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, n_output)\n",
    "        # insert control point as bias\n",
    "        bias = torch.flatten(source_points)\n",
    "        self.fc2.bias.data.copy_(bias)\n",
    "        self.fc2.weight.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x) # no activation\n",
    "        return x.view(self.args.batch_size, -1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tps_warper, a function that warp the image by distortion kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tps_warper(nn.Module):\n",
    "    def __init__(self, args, source_points):\n",
    "        super(tps_warper, self).__init__()\n",
    "        self.args = args\n",
    "        self.src_points = source_points\n",
    "        \n",
    "    def get_tensortype(self, tensor):\n",
    "        return dict(dtype=tensor.dtype, device=tensor.device)\n",
    "    \n",
    "    def pair_square_euclidean(self, x1, x2):\n",
    "        # ||x1 - x2||^2 = (x1-x2)^T(x1-x2) = x1^T*x1 + x2^T*x2 - 2*x1^T*x2\n",
    "        x1_sq = x1.mul(x1).sum(dim=-1, keepdim=True)\n",
    "        x2_sq = x2.mul(x2).sum(dim=-1, keepdim=True).transpose(1,2)\n",
    "        x1_x2 = x1.matmul(x2.transpose(1,2))\n",
    "        square_dist = -2 * x1_x2 + x1_sq + x2_sq\n",
    "        square_dist = square_dist.clamp(min=0)  # handle possible numerical errors\n",
    "        return square_dist\n",
    "    def kernel_distance(self, r_sq, eps=1e-8):\n",
    "        # Compute the TPS kernel distance function: r^2*log(r), where r is the euclidean distance\n",
    "        return 0.5 * r_sq * r_sq.add(eps).log()\n",
    "    \n",
    "    def get_tps_parameters(self, source_points, dest_points):\n",
    "        tensortype = self.get_tensortype(source_points)\n",
    "        batch_size, n_points = source_points.shape[:2]\n",
    "        # TPS warping has a close form equation:\n",
    "        # find a_1, a_x, a_y, w_i in some equation (a surface for the warping)\n",
    "        # to get coefficients (a_1, a_x, a_y, w_i), we need to solve a linear system\n",
    "        # build matrix L\n",
    "        pair_distance = self.pair_square_euclidean(source_points, dest_points)\n",
    "        k_matrix = self.kernel_distance(pair_distance)\n",
    "        dest_with_zeros = torch.cat((dest_points, torch.zeros(batch_size, 3, 2, **tensortype)), 1)\n",
    "        p_matrix = torch.cat((torch.ones(batch_size, n_points, 1, **tensortype), source_points), -1)\n",
    "        p_matrix_t = torch.cat((p_matrix, torch.zeros(batch_size, 3, 3, **tensortype)), 1).transpose(1,2)\n",
    "        l_matrix = torch.cat((k_matrix, p_matrix), -1)\n",
    "        l_matrix = torch.cat((l_matrix, p_matrix_t), 1)\n",
    "        # solve the linear system\n",
    "        weights, _ = torch.solve(dest_with_zeros, l_matrix)\n",
    "        rbf_weights = weights[:, :-3]\n",
    "        affine_weights = weights[:, -3:]\n",
    "        # with these weights, we got a function for TPS warping\n",
    "        return rbf_weights, affine_weights \n",
    "    \n",
    "    def tps_warp_points(self, source_points, kernel_points, rbf_weights, affine_weights):\n",
    "        # map all pixel to its new location\n",
    "        pair_distance = self.pair_square_euclidean(source_points, kernel_points)\n",
    "        k_matrix = self.kernel_distance(pair_distance)\n",
    "        # rerpeat on x and y\n",
    "        k_matrix = k_matrix.unsqueeze(3).repeat(1,1,1,2)\n",
    "        source_points = source_points.unsqueeze(3).repeat(1,1,1,2)\n",
    "        # add pixel dimension for broadcasting\n",
    "        rbf_weights, affine_weights = rbf_weights.unsqueeze(1), affine_weights.unsqueeze(1)\n",
    "\n",
    "        warped = k_matrix.mul(rbf_weights).sum(-2) + \\\n",
    "                 source_points.mul(affine_weights[:,:,1:,:]).sum(-2) + \\\n",
    "                 affine_weights[:,:,0,:]\n",
    "        return warped\n",
    "    \n",
    "    def tps_warp_image(self, image, kernel_points, rbf_weights, affine_weights):\n",
    "        tensortype = self.get_tensortype(kernel_points)\n",
    "        batch_size, _, h, w = image.shape\n",
    "        # create the grid to represent all the pixel\n",
    "        ys, xs = torch.meshgrid(torch.linspace(-1, 1, h, **tensortype),\n",
    "                                torch.linspace(-1, 1, w, **tensortype))\n",
    "        coords = torch.stack([xs, ys], -1).view(-1, 2)\n",
    "        coords = torch.stack([coords]*batch_size, 0)\n",
    "        warped = self.tps_warp_points(coords, kernel_points, rbf_weights, affine_weights).view(-1, h, w, 2)\n",
    "        warped_image = F.grid_sample(image, warped, align_corners=False)\n",
    "        return warped_image\n",
    "\n",
    "    def forward(self, image, dst_points):\n",
    "        rbf_weights, affine_weights = self.get_tps_parameters(dst_points, self.src_points)\n",
    "        warped_image = self.tps_warp_image(image, self.src_points, rbf_weights, affine_weights)\n",
    "        return warped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tps_stn, the structure of the whole tps-stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tps_stn(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(tps_stn, self).__init__()\n",
    "        self.args = args\n",
    "        src_points = self.get_src_points(args.batch_size, args.n_grid_density).to(device)\n",
    "        self.src_points = src_points.unsqueeze(0).repeat(args.batch_size, 1, 1)\n",
    "\n",
    "        self.follower = follower(args)\n",
    "        self.localizer = localizer(args, src_points)\n",
    "        self.tps_warper = tps_warper(args, self.src_points)\n",
    "\n",
    "    # src_points create upon the n_grid_density is given\n",
    "    def get_src_points(self, batch_size, n_grid_density=4, grid_span=0.9):\n",
    "        src_points_1d = torch.linspace(-grid_span, grid_span, steps=n_grid_density)\n",
    "        src_points_2d = torch.cartesian_prod(src_points_1d, src_points_1d)\n",
    "        return src_points_2d\n",
    "        \n",
    "    def stn(self, x):\n",
    "        kernel_points = self.localizer(x)\n",
    "        warped_x = self.tps_warper(x, kernel_points)\n",
    "        return warped_x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        warped_x = self.stn(x)\n",
    "        x = self.follower(warped_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset..\n",
      "==> Building model..\n",
      "\n",
      "Epoch: 0000\n",
      "==> Saving..\n",
      "\n",
      "Epoch: 0001\n",
      "\n",
      "Epoch: 0002\n",
      "\n",
      "Epoch: 0003\n",
      "\n",
      "Epoch: 0004\n",
      "\n",
      "Epoch: 0005\n",
      "\n",
      "Epoch: 0006\n",
      "\n",
      "Epoch: 0007\n",
      "\n",
      "Epoch: 0008\n",
      "\n",
      "Epoch: 0009\n",
      "==> Saving..\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args = opts() # TODO: replace it by argparse\n",
    "    # Set seeds\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    print('==> Preparing dataset..')\n",
    "    # Training dataset\n",
    "    mnist_train = datasets.MNIST(\"./data/MNIST\", train=True, download=True, transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ]))\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
    "    # Test dataset\n",
    "    mnist_test = datasets.MNIST(\"./data/MNIST\", train=True, download=True, transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ]))\n",
    "    test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=args.batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
    "\n",
    "    # Load model\n",
    "    if args.resume:\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        model = tps_stn(args).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        checkpoint = torch.load('./checkpoint/' + args.sess + '_' + str(args.seed) + '.pth')\n",
    "        prev_acc = checkpoint['acc']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch_start = checkpoint['epoch'] + 1\n",
    "        torch.set_rng_state(checkpoint['rng_state'])\n",
    "    else:\n",
    "        print('==> Building model..')\n",
    "        epoch_start = 0\n",
    "        prev_acc = 0.0\n",
    "        model = tps_stn(args).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Logger\n",
    "    result_folder = './results/'\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.makedirs(result_folder)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logname = model.__class__.__name__ + '_' + args.sess + \\\n",
    "        '_' + str(args.seed) + '.log'\n",
    "    logfile = os.path.join(result_folder, logname)\n",
    "    if os.path.exists(logfile):\n",
    "        os.remove(logfile)\n",
    "    logging.basicConfig(\n",
    "        format='[%(asctime)s] - %(message)s',\n",
    "        datefmt='%Y/%m/%d %H:%M:%S',\n",
    "        level=logging.INFO,\n",
    "        filename=logfile\n",
    "    )\n",
    "    logger.info(args)\n",
    "\n",
    "    # Training\n",
    "    def train(epoch):\n",
    "        print('\\nEpoch: {:04}'.format(epoch))\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_logit = model(data)\n",
    "            loss = F.nll_loss(output_logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds = F.softmax(output_logit, dim=1)\n",
    "            preds_top_p, preds_top_class = preds.topk(1, dim=1)\n",
    "\n",
    "            train_loss += loss.item() * target.size(0)\n",
    "            total += target.size(0)\n",
    "            correct += (preds_top_class.view(target.shape) == target).sum().item()\n",
    "\n",
    "        return (train_loss / batch_idx, 100. * correct / total)\n",
    "\n",
    "    # Test\n",
    "    def test(epoch):\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                output_logit = model(data)\n",
    "                loss = F.nll_loss(output_logit, target)\n",
    "                preds = F.softmax(output_logit, dim=1)\n",
    "                preds_top_p, preds_top_class = preds.topk(1, dim=1)\n",
    "    \n",
    "                test_loss += loss.item() * target.size(0)\n",
    "                total += target.size(0)\n",
    "                correct += (preds_top_class.view(target.shape) == target).sum().item()\n",
    "        \n",
    "        return (test_loss / batch_idx, 100. * correct / total)\n",
    "            \n",
    "    # Save checkpoint\n",
    "    def checkpoint(acc, epoch):\n",
    "        print('==> Saving..')\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        save_path = './checkpoint/' + args.sess + '_' + str(args.seed) + '.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'acc': acc,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'rng_state': torch.get_rng_state(),\n",
    "            }, save_path)\n",
    "    \n",
    "    # Run\n",
    "    logger.info('Epoch \\t Seconds \\t \\t Train Loss \\t Train Acc')\n",
    "    start_train_time = time.time()\n",
    "    for epoch in range(epoch_start, args.epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train(epoch)\n",
    "        epoch_time = time.time()\n",
    "        logger.info('%5d \\t %7.1f \\t \\t %10.4f \\t %9.4f',\n",
    "            epoch, epoch_time - start_epoch_time, train_loss, train_acc)\n",
    "        # Save checkpoint.\n",
    "        if train_acc - prev_acc  > 0.1:\n",
    "            prev_acc = train_acc\n",
    "            checkpoint(train_acc, epoch)\n",
    "    train_time = time.time()\n",
    "    logger.info('Total train time: %.4f minutes', (train_time - start_train_time)/60)\n",
    "\n",
    "    # Evaluation\n",
    "    logger.info('Test Loss \\t Test Acc')\n",
    "    test_loss, test_acc = test(epoch)\n",
    "    logger.info('%9.4f \\t %8.4f', test_loss, test_acc)\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6664fe25ce9354346ed42aa4b9186df47f062f6b25d553d8c501c2e4ee368ba4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('shims': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}